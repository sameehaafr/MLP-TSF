# -*- coding: utf-8 -*-
"""lstm_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bQW6fEmrmjpRXYDXvGuSbMz3-GrKuO6F
"""

from google.colab import drive  
drive.mount('/content/gdrive')

"""### Load Libraries"""

import pandas as pd
import time
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras.models import load_model
from keras.layers import LSTM, Dense
from keras.models import Sequential
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from numpy import array

"""### Load Data"""

la_2020 = pd.read_csv('/content/gdrive/MyDrive/ML@P TSF/DATA/LA_pm10_2020.csv')
la_2021 = pd.read_csv('/content/gdrive/MyDrive/ML@P TSF/DATA/LA_pm10_2021.csv')
la_2022 = pd.read_csv('/content/gdrive/MyDrive/ML@P TSF/DATA/LA_pm10_2022.csv')

"""Subsetting Data to Date and Daily Mean PM10 Concentration"""

la_2020 = la_2020[['Date', 'Daily Mean PM10 Concentration']]
la_2021 = la_2021[['Date', 'Daily Mean PM10 Concentration']]
la_2022 = la_2022[['Date', 'Daily Mean PM10 Concentration']]

"""Converting Date Column Datatype to Datetime"""

la_2020['Date'] = pd.to_datetime(la_2020['Date'])
la_2021['Date'] = pd.to_datetime(la_2021['Date'])
la_2022['Date'] = pd.to_datetime(la_2022['Date'])

"""Merging the 3 Datasets"""

# la_pm10 = pd.concat([la_2020, la_2021, la_2022])
# la_pm10.rename(columns = {'Daily Mean PM10 Concentration':'daily_pm10'}, inplace = True)

la_pm10 = pd.concat([la_2020, la_2021])
la_pm10.rename(columns = {'Daily Mean PM10 Concentration':'daily_pm10'}, inplace = True)
la_2022.rename(columns = {'Daily Mean PM10 Concentration':'daily_pm10'}, inplace = True)

"""### Data Analysis"""

# finding row with max pm10 value
la_pm10.loc[(la_pm10['daily_pm10'] == max(la_pm10['daily_pm10']))]

"""Normalizing the Data"""

#normalizing
la_pm10['daily_pm10'] = (la_pm10['daily_pm10'] - la_pm10['daily_pm10'].mean()) / la_pm10['daily_pm10'].std()
#la_2022['daily_pm10'] = (la_2022['daily_pm10'] - la_2022['daily_pm10'].mean()) / la_2022['daily_pm10'].std()

la_pm10

"""Data Splitting"""

def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

"""Define the Input Sequence"""

daily_pm10 = la_pm10['daily_pm10'].values.tolist()

daily_pm10 = daily_pm10[0:len(daily_pm10)-1]

x_train, y_train = split_sequence(daily_pm10, 10)

x_train

x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))

x_train.shape

x_train

"""### Defining Model"""

# define model
n_steps = 10
n_features = 1
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

tf.config.run_functions_eagerly(True)
tf.data.experimental.enable_debug_mode()

time1 = time.perf_counter()
model.fit(x_train, y_train, epochs=200, verbose=0)
time2 = time.perf_counter()
print("model running time: ", time2-time1)

"""Saving Model"""

model.save('/content/gdrive/MyDrive/ML@P TSF/models/lstm_model_1.h5')

"""Making Predictions"""

from keras.models import load_model
model = load_model('/content/gdrive/MyDrive/ML@P TSF/models/lstm_model_1.h5')

yhat = model.predict(la_2022['daily_pm10'][0:20], verbose=0)
print(yhat)

la_2022['daily_pm10_normalized'] = (la_2022['daily_pm10'] - la_2022['daily_pm10'].mean()) / la_2022['daily_pm10'].std()

actual = (la_2022['daily_pm10_normalized'][0:20]).to_numpy()

actual

yhat

plt.plot(actual, label = "actual")
plt.plot(yhat, label = "predicted")

plt.xlabel('x - axis')
plt.ylabel('y - axis')
plt.title('predicted vs actual')
plt.legend()
plt.show()

"""Validating Model"""

mean_squared_error(actual, yhat)